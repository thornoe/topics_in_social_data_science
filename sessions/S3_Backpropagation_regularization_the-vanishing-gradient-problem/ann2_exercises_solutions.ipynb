{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **DO NOT EDIT IF INSIDE tsds folder**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 3: Artificial Neural Networks 2\n",
    "\n",
    "*Wednesday, February 19, 2019*\n",
    "\n",
    "Today, you will complete your understanding of Nielsen's code by understanding how backpropagation is implemented. Then you will move on to problems about regularization in neural networks and something we call \"the vanishing gradient problem\".\n",
    "- Part 3.1: Backpropagation\n",
    "- Part 3.2: Regularization\n",
    "- Part 3.3: Vanishing gradients\n",
    "\n",
    "**Questions**: Outside of class, use [issue](https://github.com/abjer/tsds/issues) on GitHub for asking questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-21T09:34:25.918150Z",
     "start_time": "2019-02-21T09:34:25.812413Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pylab as plt\n",
    "from scipy.interpolate import interp1d\n",
    "import mnist_loader\n",
    "from datetime import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3.1: Backpropagation\n",
    "\n",
    "Last week I introduced you to [Nielsen's](http://neuralnetworksanddeeplearning.com/chap1.html) general implementation of a feed forward neural network. **Your understanding** of neural networks should now be something along the lines of: (1) a datapoint propagates forward through the network, then (2) a cost (how bad the prediction is) is evaluated and its gradient wrt. each weight is computed, and finally (3) the weights are updated according to how much they influence the cost.\n",
    "\n",
    "However, something important is missing from our understanding at this point. Remember, that *gradient descent* – the algorithm for minimizing the cost function, which we can think of as ball rolling downhill – needs to known which direction is downhill on the cost function. The gradient tells us this. **So how do we compute the cost function's gradient?** Enter: *backpropagation*. Backpropagation is an algorithm which computes the gradient of the cost function wrt. each weight in the network, from right to left, by iteratively applying *the chain rule*. It is called *back*-propagation because it propagates gradients *back*-wards in this fashion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pen and paper calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I want you to do some pen and paper calculations to hand-compute gradients in a real neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](https://raw.githubusercontent.com/abjer/tsds/master/material_exercises/week_3/2_3_1_net.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 3.1.1**: The network above has a defined input and weights. If the true label for the datapoint `[4, 2]` is 1, what is the cost?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](https://raw.githubusercontent.com/abjer/tsds/master/material_exercises/week_3/2_3_1_net_compgraph_forward.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 3.1.2**: Knowing about backpropagation, we actually have everything we need here to compute the gradients of the weights by hand. So go ahead and do that. Report your answer either as a diagram that includes the gradients (you can draw on my figure somehow and insert the resulting image), or just by writing what the gradient of each weight is.\n",
    ">\n",
    "> *Hint: When computing gradients with backprop, it can be a bit easier to think of the network as a computational graph. My computational graph looks like [this](https://github.com/abjer/tsds/blob/master/material_exercises/week_3/2_3_1_net_compgraph.png?raw=true).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Understanding the code implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-19T12:23:23.451037Z",
     "start_time": "2019-02-19T12:23:23.446177Z"
    }
   },
   "source": [
    "I've copied my version of Nielsen's code below. It's an **exact copy** from last week, except I've removed by previous `#Q:` comments and inserted some new ones. In the exercises below you will have to figure out what the `backprop` method is doing, and compute some gradients for very simple neural networks with pen and paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-19T12:41:50.923481Z",
     "start_time": "2019-02-19T12:41:50.876424Z"
    }
   },
   "outputs": [],
   "source": [
    "# Miscellaneous functions\n",
    "def sigmoid(z):\n",
    "    \"\"\"The sigmoid function.\"\"\"\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def sigmoid_prime(z):\n",
    "    \"\"\"Derivative of the sigmoid function.\"\"\"\n",
    "    return sigmoid(z) * (1 - sigmoid(z))\n",
    "\n",
    "def step(z, threshold=0.5):\n",
    "    if z > threshold:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "# Feed forward neural network class\n",
    "class Network(object):\n",
    "\n",
    "    def __init__(self, sizes):\n",
    "        \"\"\"The list ``sizes`` contains the number of neurons in the\n",
    "        respective layers of the network.  For example, if the list\n",
    "        was [2, 3, 1] then it would be a three-layer network, with the\n",
    "        first layer containing 2 neurons, the second layer 3 neurons,\n",
    "        and the third layer 1 neuron.  The biases and weights for the\n",
    "        network are initialized randomly, using a Gaussian\n",
    "        distribution with mean 0, and variance 1.  Note that the first\n",
    "        layer is assumed to be an input layer, and by convention we\n",
    "        won't set any biases for those neurons, since biases are only\n",
    "        ever used in computing the outputs from later layers.\"\"\"\n",
    "        \n",
    "        self.num_layers = len(sizes)\n",
    "        self.sizes = sizes\n",
    "        \n",
    "        self.biases = [np.random.randn(y, 1) for y in sizes[1:]]\n",
    "        self.weights = [np.random.randn(y, x) for x, y in zip(sizes[:-1], sizes[1:])]\n",
    "\n",
    "    def feedforward(self, a):\n",
    "        \"\"\"Return the output of the network if ``a`` is input.\"\"\"\n",
    "        \n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            a = sigmoid(np.dot(w, a) + b)\n",
    "        return a\n",
    "\n",
    "    def SGD(self, training_data, epochs, mini_batch_size, eta, test_data=None, silent=False):\n",
    "        \"\"\"Train the neural network using mini-batch stochastic\n",
    "        gradient descent.  The ``training_data`` is a list of tuples\n",
    "        ``(x, y)`` representing the training inputs and the desired\n",
    "        outputs.  The other non-optional parameters are\n",
    "        self-explanatory.  If ``test_data`` is provided then the\n",
    "        network will be evaluated against the test data after each\n",
    "        epoch, and partial progress printed out.  This is useful for\n",
    "        tracking progress, but slows things down substantially.\"\"\"\n",
    "        \n",
    "        n = len(training_data)\n",
    "        if test_data:\n",
    "            n_test = len(test_data)\n",
    "        \n",
    "        for j in range(epochs):\n",
    "            \n",
    "            random.shuffle(training_data)\n",
    "            mini_batches = [\n",
    "                training_data[k:k+mini_batch_size]\n",
    "                for k in range(0, n, mini_batch_size)\n",
    "            ]\n",
    "            \n",
    "            for mini_batch in mini_batches:\n",
    "                self.update_mini_batch(mini_batch, eta)\n",
    "            \n",
    "            if not silent:\n",
    "                if test_data:\n",
    "                    print(\"Epoch {0}: {1} / {2}\".format(j, self.evaluate(test_data), n_test))\n",
    "                else:\n",
    "                    print(\"Epoch {0} complete\".format(j))\n",
    "\n",
    "    def update_mini_batch(self, mini_batch, eta):\n",
    "        \"\"\"Update the network's weights and biases by applying\n",
    "        gradient descent using backpropagation to a single mini batch.\n",
    "        The ``mini_batch`` is a list of tuples ``(x, y)``, and ``eta``\n",
    "        is the learning rate.\"\"\"\n",
    "        \n",
    "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        \n",
    "        for x, y in mini_batch:\n",
    "            delta_nabla_b, delta_nabla_w = self.backprop(x, y)\n",
    "            nabla_b = [nb+dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]\n",
    "            nabla_w = [nw+dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]\n",
    "            \n",
    "        self.weights = [\n",
    "            w - eta / len(mini_batch) * nw\n",
    "            for w, nw in zip(self.weights, nabla_w)\n",
    "        ]\n",
    "        self.biases = [\n",
    "            b - eta / len(mini_batch) * nb\n",
    "            for b, nb in zip(self.biases, nabla_b)\n",
    "        ]\n",
    "\n",
    "    def backprop(self, x, y):\n",
    "        \"\"\"Return a tuple ``(nabla_b, nabla_w)`` representing the\n",
    "        gradient for the cost function C_x.  ``nabla_b`` and\n",
    "        ``nabla_w`` are layer-by-layer lists of numpy arrays, similar\n",
    "        to ``self.biases`` and ``self.weights``.\"\"\"\n",
    "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        \n",
    "        # Q: In the feed forward step it seems like we are storing all the\n",
    "        # intermediate values. Why?\n",
    "        \n",
    "        # feedforward\n",
    "        activation = x\n",
    "        activations = [x] # list to store all the activations, layer by layer\n",
    "        zs = [] # list to store all the z vectors, layer by layer\n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            z = np.dot(w, activation)+b\n",
    "            zs.append(z)\n",
    "            activation = sigmoid(z)\n",
    "            activations.append(activation)\n",
    "        \n",
    "        \n",
    "        # Q: What does the variable `delta` store? Why is the last bias gradient\n",
    "        # exactly `delta`?\n",
    "        \n",
    "        # backward pass\n",
    "        delta = self.cost_derivative(activations[-1], y) * sigmoid_prime(zs[-1])\n",
    "        nabla_b[-1] = delta\n",
    "        \n",
    "        # Q: Seems like we are multiplying each of the outputs from the previous\n",
    "        # layer, with the delta. Can you explain why we do this? \n",
    "        nabla_w[-1] = np.dot(delta, activations[-2].transpose())\n",
    "        \n",
    "        # Note that the variable l in the loop below is used a little\n",
    "        # differently to the notation in Chapter 2 of the book. Here,\n",
    "        # l = 1 means the last layer of neurons, l = 2 is the\n",
    "        # second-last layer, and so on. It's a renumbering of the\n",
    "        # scheme in the book, used here to take advantage of the fact\n",
    "        # that Python can use negative indices in lists.\n",
    "        \n",
    "        # Q: Why start the loop at the second last layer?\n",
    "        for l in range(2, self.num_layers):\n",
    "            z = zs[-l]\n",
    "            sp = sigmoid_prime(z)\n",
    "            delta = np.dot(self.weights[-l+1].transpose(), delta) * sp  # Q: What happens on this line?\n",
    "            nabla_b[-l] = delta\n",
    "            nabla_w[-l] = np.dot(delta, activations[-l-1].transpose())\n",
    "        return nabla_b, nabla_w\n",
    "\n",
    "    def evaluate(self, test_data):\n",
    "        \"\"\"Return the number of test inputs for which the neural\n",
    "        network outputs the correct result. Note that the neural\n",
    "        network's output is assumed to be the index of whichever\n",
    "        neuron in the final layer has the highest activation.\"\"\"\n",
    "        if self.sizes[-1] == 1:\n",
    "            test_results = [\n",
    "                (step(self.feedforward(x)), y)\n",
    "                for x, y in test_data\n",
    "            ]\n",
    "        else:\n",
    "            test_results = [\n",
    "                (np.argmax(self.feedforward(x)), y)\n",
    "                for x, y in test_data\n",
    "            ]\n",
    "        return sum(int(y_pred == y) for (y_pred, y) in test_results)\n",
    "\n",
    "    def cost_derivative(self, output_activations, y):\n",
    "        \"\"\"Return the vector of partial derivatives \\partial C_x /\n",
    "        \\partial a for the output activations.\"\"\"\n",
    "        return output_activations - y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 3.1.1:** Provide answers to the code comments starting with `#Q: `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-21T08:57:19.560249Z",
     "start_time": "2019-02-21T08:57:19.550975Z"
    }
   },
   "outputs": [],
   "source": [
    "# Q: In the feed forward step it seems like we are storing all the\n",
    "# intermediate values. Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw in the lecture, the fed forward valued are used as input to the derivarive of each neuron, so we need to store them in order to compute the gradients when we do backpropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q: What does the variable `delta` store? Why is the last bias gradient\n",
    "# exactly `delta`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point in the code and onwarsd, `delta` is the gradient of the loss function wrt. the weight/neuron-output that the iteration of the backprop algorithm has reached. In the first iteration of backprop that Nielsen implements, he computed the `delta`(s) of the value(s) that goes into the last sigmoid. The multiplication between the cost derivative (where the cost derivative is missing a `2*`, who knows why), and the sigmoid derivative is Nielsen applying the chain rule. Note also that `delta` is a vector, such that if multiple outputs existed (and they do in the case of number classification), you compute a gradient for each output neuron. Finally, as you may recall from the lecture, the derivative of addition operators are 1, so the gradient of the bias(es) just becomes the gradient of the output(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-21T09:08:07.105904Z",
     "start_time": "2019-02-21T09:08:07.103673Z"
    }
   },
   "outputs": [],
   "source": [
    "# Q: Seems like we are multiplying each of the outputs from the previous\n",
    "# layer, with the delta. Can you explain why we do this? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember how the derivative of a weight is the variable multiplied onto it? This is what Nielsen utilizes here. Given the derivative(s) from the output(s), we know that the derivative of an output wrt. a weight is just the input which we multiply that weight by. Think of it like \"if I increment this weight by one, the output gets changed by the amount that I multiply the weight by\". So to propagate the gradient backwards and onto the first layer of weights, we simply multiply it by the incoming activations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-21T09:13:13.898039Z",
     "start_time": "2019-02-21T09:13:13.893234Z"
    }
   },
   "outputs": [],
   "source": [
    "# Q: Why start the loop at the second last layer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this loop iteratively applies what I just explained above. And there we already handled the last layer, remember? So we start off where we left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-21T09:16:08.151389Z",
     "start_time": "2019-02-21T09:16:08.148997Z"
    }
   },
   "outputs": [],
   "source": [
    "# Q: What happens on this line?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are computing the gradients on the neuron-outputs (the `z`s) going into the sigmoids of the given layer.\n",
    "So to do that we must take the previous gradient and multiply it with the weights (remember $y=xw$), then\n",
    "multiply again by the derivative of the sigmoid function. This new delta, as we saw above, propagates back\n",
    "to the bias without complication – since the bias derivative wrt. to the output of the neuron it feeds into\n",
    "is one. To get the weight gradients the gradient, as before, gets multiplied, by the activations from the\n",
    "incoming layers. The new gradients get stored, and so it goes until we run out of layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3.2: Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this next part, it would be too cumbersome to continue using Nielsen's code. Instead, we will be using\n",
    "my favorite deep learning framework **PyTorch** to build some neural networks with which we can play around\n",
    "with regularization.\n",
    "\n",
    "To get torch running you need to first install it. It's should be fairly straight forward, but depending on\n",
    "your machine you may have to run different commands to install it. Check out the installation guide [here](https://pytorch.org/).\n",
    "\n",
    "If everything went well you should be able execute the cell below and to import PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-19T22:20:04.502262Z",
     "start_time": "2019-02-19T22:20:03.966734Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No errors? Great! Then let's make a small neural network that we know all to well at this point, and see if we can classify points with it. First, we generate some data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T06:24:22.093846Z",
     "start_time": "2019-02-20T06:24:22.085904Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_X_nonlinear(N=200, R=5):\n",
    "\n",
    "    X_inner = torch.randn(int(N/2), 2)\n",
    "\n",
    "    X_outer = torch.tensor([\n",
    "        [R*np.cos(theta), R*np.sin(theta)]\n",
    "        for theta in np.linspace(0, 2 * np.pi, int(N/2))\n",
    "    ]) + torch.randn(int(N/2), 2)\n",
    "\n",
    "    X = torch.cat([X_inner, X_outer], dim=0)\n",
    "   \n",
    "    y = torch.cat([\n",
    "        torch.zeros(int(N/2)).reshape(-1, 1),\n",
    "        torch.ones(int(N/2)).reshape(-1, 1)\n",
    "    ])\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# Number of training datapoints\n",
    "N = 500\n",
    "\n",
    "# Generate the data (note that code is using torch arrays now)\n",
    "x, y = generate_X_nonlinear(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we create and run the network on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T06:24:33.192681Z",
     "start_time": "2019-02-20T06:24:33.139364Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 132.64141845703125\n",
      "10 243.86502075195312\n",
      "20 74.21397399902344\n",
      "30 20.397912979125977\n",
      "40 10.828099250793457\n",
      "50 8.089787483215332\n",
      "60 7.727997779846191\n",
      "70 7.685032844543457\n",
      "80 7.67869234085083\n",
      "90 7.663687229156494\n"
     ]
    }
   ],
   "source": [
    "# The layers and their number of neurons\n",
    "sizes = [2, 3, 1]\n",
    "\n",
    "# The `model`. This is new! In torch, defining a neural network is a easy as just\n",
    "# declaring which layers you want, and then it handles everything else. So in this\n",
    "# case we want a linear layer that gets squashed through a sigmoid, which feeds as\n",
    "# input to another layer that again gets squashed by a sigmoid.\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(sizes[0], sizes[1]),\n",
    "    torch.nn.Sigmoid(),\n",
    "    torch.nn.Linear(sizes[1], sizes[2]),\n",
    "    torch.nn.Sigmoid()\n",
    ")\n",
    "\n",
    "# Then we have to declare which loss function we want to use, and here we are just goind\n",
    "\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "\n",
    "learning_rate = 1e-1\n",
    "for t in range(100):\n",
    "    # Forward pass\n",
    "    y_pred = model(x)\n",
    "\n",
    "    # Compute loss\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    if t % 10 == 0:\n",
    "        print(t, loss.item())\n",
    "\n",
    "    # Zero the gradients before running the backward pass.\n",
    "    model.zero_grad()\n",
    "\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # Do gradient descent\n",
    "    with torch.no_grad():\n",
    "        for param in model.parameters():\n",
    "            param -= learning_rate * param.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T06:24:40.616140Z",
     "start_time": "2019-02-20T06:24:40.610990Z"
    }
   },
   "outputs": [],
   "source": [
    "class cmap_in_range:\n",
    "    \"\"\"Create map to range of colors inside given domain.\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    >>> cmap = cmap_in_range([0, 1])\n",
    "    >>> cmap(0.1)\n",
    "    (0.30392156862745101, 0.30315267411304353, 0.98816547208125938, 1.0)\n",
    "    \"\"\"\n",
    "    def __init__(self, cmap_domain, cmap_range=[0, 1], cmap_style='rainbow'):\n",
    "        self.cmap_domain = cmap_domain\n",
    "        self.cmap_range = cmap_range\n",
    "        self.m = interp1d(cmap_domain, cmap_range)\n",
    "        self.cmap = plt.get_cmap(cmap_style)\n",
    "        \n",
    "    def __call__(self, value):\n",
    "        if not self.cmap_domain[0] <= value <= self.cmap_domain[1]:\n",
    "            raise Exception(\"Value must be inside cmap_domain.\")\n",
    "        return self.cmap(self.m(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T06:24:41.528665Z",
     "start_time": "2019-02-20T06:24:41.033722Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cmap = cmap_in_range([0, 1])\n",
    "\n",
    "y_true = y.reshape(-1).numpy()\n",
    "y_pred = model(x).data.numpy().reshape(-1)\n",
    "\n",
    "plt.figure(figsize=(9, 3))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"True\", fontsize=12)\n",
    "plt.scatter(x[:, 0], x[:, 1], color=list(map(cmap, y_true)))\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Predicted\", fontsize=12)\n",
    "plt.scatter(x[:, 0], x[:, 1], color=list(map(cmap, y_pred)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PyTorch API for setting up and training neural nets is much nicer than Nielsen's code,\n",
    "and at the same time it runs much faster and seems to give better results.\n",
    "Let's implement the MNIST example in PyTorch and see how well it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-21T09:45:32.261826Z",
     "start_time": "2019-02-21T09:45:31.341920Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load MNIST data. Note we use the `load_data` method and not the \n",
    "# `load_data_wrapper`. The difference is that `load_data` gives us\n",
    "# the data in clean matrix format right away.\n",
    "training_data, validation_data, test_data = mnist_loader.load_data()\n",
    "\n",
    "x = torch.from_numpy(training_data[0])\n",
    "y_ = torch.from_numpy(training_data[1])\n",
    "\n",
    "x_test = torch.from_numpy(test_data[0])\n",
    "y_test_ = torch.from_numpy(test_data[1])\n",
    "\n",
    "# y is a (N, 1) vector. In the following setup, however, we need it to be a\n",
    "# (N, 10) vector such that each digit has it's own column so labels are one-\n",
    "# hot vectors. For example, we should encode the label `2` not as [2], but as\n",
    "# [0, 0, 1, 0, 0, 0, 0, 0, 0, 0] instead.\n",
    "\n",
    "y = torch.zeros(x.shape[0], 10)\n",
    "y[torch.arange(x.shape[0]), y_] = 1\n",
    "\n",
    "y_test = torch.zeros(x_test.shape[0], 10)\n",
    "y_test[torch.arange(x_test.shape[0]), y_test_] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-21T09:48:06.027914Z",
     "start_time": "2019-02-21T09:47:44.414412Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 train: 127307.8984375 | test: 25383.9296875\n",
      "10 train: 123641.0078125 | test: 24648.4375\n",
      "20 train: 120118.7890625 | test: 23942.80078125\n",
      "30 train: 116761.7421875 | test: 23270.98046875\n",
      "40 train: 113579.90625 | test: 22634.814453125\n",
      "50 train: 110574.4296875 | test: 22034.376953125\n",
      "60 train: 107740.21875 | test: 21468.51953125\n",
      "70 train: 105068.40625 | test: 20935.369140625\n",
      "80 train: 102548.2421875 | test: 20432.7109375\n",
      "90 train: 100168.4453125 | test: 19958.236328125\n",
      "100 train: 97917.8828125 | test: 19509.685546875\n",
      "110 train: 95786.0390625 | test: 19084.93359375\n",
      "120 train: 93763.203125 | test: 18682.01953125\n",
      "130 train: 91840.5234375 | test: 18299.1640625\n",
      "140 train: 90010.015625 | test: 17934.759765625\n",
      "150 train: 88264.5390625 | test: 17587.369140625\n",
      "160 train: 86597.6953125 | test: 17255.712890625\n",
      "170 train: 85003.8359375 | test: 16938.646484375\n",
      "180 train: 83477.90625 | test: 16635.162109375\n",
      "190 train: 82015.453125 | test: 16344.3564453125\n",
      "200 train: 80612.46875 | test: 16065.427734375\n",
      "210 train: 79265.375 | test: 15797.6513671875\n",
      "220 train: 77970.9140625 | test: 15540.369140625\n",
      "230 train: 76726.078125 | test: 15292.974609375\n",
      "240 train: 75528.1015625 | test: 15054.9091796875\n",
      "250 train: 74374.4140625 | test: 14825.65234375\n",
      "260 train: 73262.625 | test: 14604.72265625\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "sizes = [784, 30, 10]\n",
    "learning_rate = 1e-4\n",
    "epochs = 1000\n",
    "# mini_batch_size = 100\n",
    "tmax = 20  # seconds\n",
    "\n",
    "# The `model`. This is new! In torch, defining a neural network is a easy as just\n",
    "# declaring which layers you want, and then it handles everything else. So in this\n",
    "# case we want a linear layer that gets squashed through a sigmoid, which feeds as\n",
    "# input to another layer that again gets squashed by a sigmoid. If we needed more\n",
    "# layers we would put more stuff into the `torch.nn.Sequential` method.\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(sizes[0], sizes[1]),\n",
    "    torch.nn.Sigmoid(),\n",
    "    torch.nn.Linear(sizes[1], sizes[2]),\n",
    "    torch.nn.Sigmoid()\n",
    ")\n",
    "\n",
    "# Then we have to declare which loss function we want to use, and here we are just going\n",
    "# to use the sum of squares. Here we are just taking an implementation of this off the\n",
    "# shelf from the PyTorch package, but we could easily define one ourself.\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "\n",
    "# Define an Optimizer to abstract away all the steps involved in training the network \n",
    "# (forward pass, backward pass, weight update). Here we use the Adam optimizer, which\n",
    "# is a flavor of gradient descent that maintains an adaptive learning rate for each weight\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train\n",
    "t_start = dt.now()\n",
    "for t in range(epochs):\n",
    "    \n",
    "    # Forward pass\n",
    "    y_pred = model(x)\n",
    "\n",
    "    # Compute loss\n",
    "    loss = loss_fn(y_pred, y)\n",
    "\n",
    "    # Before the backward pass, use the optimizer object to zero all of the\n",
    "    # gradients for the variables it will update (which are the learnable\n",
    "    # weights of the model). This is because by default, gradients are\n",
    "    # accumulated in buffers (i.e, not overwritten) whenever .backward()\n",
    "    # is called. Checkout docs of torch.autograd.backward for more details.\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # Calling the step function on an Optimizer makes an update to its\n",
    "    # parameters\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Print progress\n",
    "    if t % 10 == 0:\n",
    "        y_pred = model(x_test)\n",
    "        loss_test = loss_fn(y_pred, y_test)\n",
    "        print(t, \"train:\", loss.item(), \"| test:\", loss_test.item())\n",
    "        if (dt.now() - t_start).seconds > tmax:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code will run for a while, and it's not nearly as fast as it could be. The reason for \n",
    "this is that it is not using mini batches, thus it is doing gradient descent on the entire\n",
    "dataset. That takes time "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: The \"solutions\" below are more like explorations where I play with mini-batching and regularization in different ways. I encourage you to use them in the same way, so to get an idea of what I did. Play with the parameters, let the networks train for much longer than I did and build a practical sense of what happens when we twist these knobs.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 3.2.1**: Implement stochastic gradient descent with `mini_batch_size = 100`. Comment on the performance difference you see when compared to regular gradient descent.\n",
    ">\n",
    "> *Hint: If you want to compute the accuracy, you need to convert the predictions back into a single column label vector and compare it with the true labels. Here is how to do that: `_, y_pred_ = y_pred.max(1); print((y_pred_ == y_).numpy().mean())`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-21T09:49:01.742268Z",
     "start_time": "2019-02-21T09:48:37.661289Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 train: 55400.0625 | test: 11061.724609375\n",
      "10 train: 20146.51171875 | test: 3963.51318359375\n",
      "20 train: 10417.4833984375 | test: 2010.6806640625\n",
      "30 train: 7913.51953125 | test: 1533.88525390625\n",
      "40 train: 6821.16796875 | test: 1336.722412109375\n",
      "50 train: 6162.6748046875 | test: 1220.811767578125\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "sizes = [784, 30, 10]\n",
    "learning_rate = 1e-4\n",
    "epochs = 1000\n",
    "mini_batch_size = 100\n",
    "tmax = 20  # seconds\n",
    "\n",
    "# The `model`. This is new! In torch, defining a neural network is a easy as just\n",
    "# declaring which layers you want, and then it handles everything else. So in this\n",
    "# case we want a linear layer that gets squashed through a sigmoid, which feeds as\n",
    "# input to another layer that again gets squashed by a sigmoid. If we needed more\n",
    "# layers we would put more stuff into the `torch.nn.Sequential` method.\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(sizes[0], sizes[1]),\n",
    "    torch.nn.Sigmoid(),\n",
    "    torch.nn.Linear(sizes[1], sizes[2]),\n",
    "    torch.nn.Sigmoid()\n",
    ")\n",
    "\n",
    "# Then we have to declare which loss function we want to use, and here we are just going\n",
    "# to use the sum of squares. Here we are just taking an implementation of this off the\n",
    "# shelf from the PyTorch package, but we could easily define one ourself.\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "\n",
    "# Define an Optimizer to abstract away all the steps involved in training the network \n",
    "# (forward pass, backward pass, weight update). Here we use the Adam optimizer, which\n",
    "# is a flavor of gradient descent that maintains an adaptive learning rate for each weight\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train\n",
    "t_start = dt.now()\n",
    "for t in range(epochs):\n",
    "    \n",
    "    # Randomly permute the row indices to get something like:\n",
    "    # tensor([16214, 18491, 16308,  ..., 19629, 17565, 24696])\n",
    "    permutation = torch.randperm(x.size()[0])\n",
    "    \n",
    "    # Start looping over the mini-batches! Each index `k` is\n",
    "    # `mini_batch_size` values apart.\n",
    "    for k in np.arange(0, x.size()[0], mini_batch_size):\n",
    "        \n",
    "        # Extract mini-batch data. The rest is the same\n",
    "        mini_batch_indices = permutation[k:k+mini_batch_size]\n",
    "        x_ = x[mini_batch_indices, :]\n",
    "        y_ = y[mini_batch_indices, :]\n",
    "        \n",
    "        # Forward pass\n",
    "        y_pred = model(x_)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_fn(y_pred, y_)\n",
    "\n",
    "        # Before the backward pass, use the optimizer object to zero all of the\n",
    "        # gradients for the variables it will update (which are the learnable\n",
    "        # weights of the model). This is because by default, gradients are\n",
    "        # accumulated in buffers (i.e, not overwritten) whenever .backward()\n",
    "        # is called. Checkout docs of torch.autograd.backward for more details.\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Calling the step function on an Optimizer makes an update to its\n",
    "        # parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "    # Print progress (here evaluating on all the data so we can compare)\n",
    "    if t % 10 == 0:\n",
    "        loss = loss_fn(model(x), y)\n",
    "        loss_test = loss_fn(model(x_test), y_test)\n",
    "        print(t, \"train:\", loss.item(), \"| test:\", loss_test.item())\n",
    "        if (dt.now() - t_start).seconds > tmax:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So here, I let the code above without mini-batching and the new code *with* mini-batching each run for 20 seconds\n",
    "and compare the error. Without mini-batching we can run through many more *epochs* than with mini-batching, but\n",
    "the cost is very high after 20 seconds, whereas when we implement mini-batching, **the cost decays extremely fast**,\n",
    "and **over fewer epochs**. Nice right!? Note that I've slightly changed the code, so it now prints performance on\n",
    "the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T07:06:41.508050Z",
     "start_time": "2019-02-20T07:06:41.479230Z"
    }
   },
   "source": [
    "We can apply the L2 regularization to the optimization by specifying a `weight_decay` parameter in the optimizer ([see docs](https://pytorch.org/docs/stable/optim.html#torch.optim.Adam)). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 3.2.2**: When applying the L2 norm, say at `weight_decay=0.2` and changing nothing else, which changes to optimization speed and convergence do you notice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-21T09:49:47.529419Z",
     "start_time": "2019-02-21T09:49:22.112485Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 train: 62460.171875 | test: 12460.697265625\n",
      "10 train: 26238.98828125 | test: 5181.84228515625\n",
      "20 train: 15722.1865234375 | test: 3033.17236328125\n",
      "30 train: 13200.2705078125 | test: 2527.4931640625\n",
      "40 train: 12431.6796875 | test: 2375.56689453125\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "sizes = [784, 30, 10]\n",
    "learning_rate = 1e-4\n",
    "epochs = 1000\n",
    "mini_batch_size = 100\n",
    "tmax = 20  # seconds\n",
    "\n",
    "# The `model`. This is new! In torch, defining a neural network is a easy as just\n",
    "# declaring which layers you want, and then it handles everything else. So in this\n",
    "# case we want a linear layer that gets squashed through a sigmoid, which feeds as\n",
    "# input to another layer that again gets squashed by a sigmoid. If we needed more\n",
    "# layers we would put more stuff into the `torch.nn.Sequential` method.\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(sizes[0], sizes[1]),\n",
    "    torch.nn.Sigmoid(),\n",
    "    torch.nn.Linear(sizes[1], sizes[2]),\n",
    "    torch.nn.Sigmoid()\n",
    ")\n",
    "\n",
    "# Then we have to declare which loss function we want to use, and here we are just going\n",
    "# to use the sum of squares. Here we are just taking an implementation of this off the\n",
    "# shelf from the PyTorch package, but we could easily define one ourself.\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "\n",
    "# Define an Optimizer to abstract away all the steps involved in training the network \n",
    "# (forward pass, backward pass, weight update). Here we use the Adam optimizer, which\n",
    "# is a flavor of gradient descent that maintains an adaptive learning rate for each weight\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.2)\n",
    "\n",
    "# Train\n",
    "t_start = dt.now()\n",
    "for t in range(epochs):\n",
    "    \n",
    "    # Randomly permute the row indices to get something like:\n",
    "    # tensor([16214, 18491, 16308,  ..., 19629, 17565, 24696])\n",
    "    permutation = torch.randperm(x.size()[0])\n",
    "    \n",
    "    # Start looping over the mini-batches! Each index `k` is\n",
    "    # `mini_batch_size` values apart.\n",
    "    for k in np.arange(0, x.size()[0], mini_batch_size):\n",
    "        \n",
    "        # Extract mini-batch data. The rest is the same\n",
    "        mini_batch_indices = permutation[k:k+mini_batch_size]\n",
    "        x_ = x[mini_batch_indices, :]\n",
    "        y_ = y[mini_batch_indices, :]\n",
    "        \n",
    "        # Forward pass\n",
    "        y_pred = model(x_)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_fn(y_pred, y_)\n",
    "\n",
    "        # Before the backward pass, use the optimizer object to zero all of the\n",
    "        # gradients for the variables it will update (which are the learnable\n",
    "        # weights of the model). This is because by default, gradients are\n",
    "        # accumulated in buffers (i.e, not overwritten) whenever .backward()\n",
    "        # is called. Checkout docs of torch.autograd.backward for more details.\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Calling the step function on an Optimizer makes an update to its\n",
    "        # parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "    # Print progress (here evaluating on all the data so we can compare)\n",
    "    if t % 10 == 0:\n",
    "        loss = loss_fn(model(x), y)\n",
    "        loss_test = loss_fn(model(x_test), y_test)\n",
    "        print(t, \"train:\", loss.item(), \"| test:\", loss_test.item())\n",
    "        if (dt.now() - t_start).seconds > tmax:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With regularization, we note that the error decays slower. We could run it for longer and we would probably observe\n",
    "that the training error plateaued at a higher level than without reguarization, while the test error would potentially\n",
    "improve, though maybe not exactly for `weight_decay = 0.2`, but for some other value. Hence, we could embark on an\n",
    "elaborate hyper-parameter tuning quest, to find the weight decay constant (from the lecture: $\\lambda$) which minimized\n",
    "the test error. But let's save that for another time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can apply dropout to individual layers by having `torch.nn.Dropout(p=my_dropout)` listed in `Sequential` immediately before the given layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 3.2.3**: Apply dropout at a rate of 0.5 and comment again on optimization speed and convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-21T09:57:50.194941Z",
     "start_time": "2019-02-21T09:57:27.502265Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 train: 61529.38671875 | test: 12295.806640625\n",
      "10 train: 30462.8125 | test: 6058.34765625\n",
      "20 train: 20971.576171875 | test: 4132.5830078125\n",
      "30 train: 17695.595703125 | test: 3474.6328125\n",
      "40 train: 16154.3291015625 | test: 3170.207275390625\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "sizes = [784, 30, 10]\n",
    "learning_rate = 1e-4\n",
    "epochs = 1000\n",
    "mini_batch_size = 100\n",
    "tmax = 20  # seconds\n",
    "\n",
    "# The `model`. This is new! In torch, defining a neural network is a easy as just\n",
    "# declaring which layers you want, and then it handles everything else. So in this\n",
    "# case we want a linear layer that gets squashed through a sigmoid, which feeds as\n",
    "# input to another layer that again gets squashed by a sigmoid. If we needed more\n",
    "# layers we would put more stuff into the `torch.nn.Sequential` method.\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(sizes[0], sizes[1]),\n",
    "    torch.nn.Sigmoid(),\n",
    "    torch.nn.Dropout(0.5),\n",
    "    torch.nn.Linear(sizes[1], sizes[2]),\n",
    "    torch.nn.Sigmoid()\n",
    ")\n",
    "\n",
    "# Then we have to declare which loss function we want to use, and here we are just going\n",
    "# to use the sum of squares. Here we are just taking an implementation of this off the\n",
    "# shelf from the PyTorch package, but we could easily define one ourself.\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "\n",
    "# Define an Optimizer to abstract away all the steps involved in training the network \n",
    "# (forward pass, backward pass, weight update). Here we use the Adam optimizer, which\n",
    "# is a flavor of gradient descent that maintains an adaptive learning rate for each weight\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train\n",
    "t_start = dt.now()\n",
    "for t in range(epochs):\n",
    "    \n",
    "    # Randomly permute the row indices to get something like:\n",
    "    # tensor([16214, 18491, 16308,  ..., 19629, 17565, 24696])\n",
    "    permutation = torch.randperm(x.size()[0])\n",
    "    \n",
    "    # Start looping over the mini-batches! Each index `k` is\n",
    "    # `mini_batch_size` values apart.\n",
    "    for k in np.arange(0, x.size()[0], mini_batch_size):\n",
    "        \n",
    "        # Extract mini-batch data. The rest is the same\n",
    "        mini_batch_indices = permutation[k:k+mini_batch_size]\n",
    "        x_ = x[mini_batch_indices, :]\n",
    "        y_ = y[mini_batch_indices, :]\n",
    "        \n",
    "        # Forward pass\n",
    "        y_pred = model(x_)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_fn(y_pred, y_)\n",
    "\n",
    "        # Before the backward pass, use the optimizer object to zero all of the\n",
    "        # gradients for the variables it will update (which are the learnable\n",
    "        # weights of the model). This is because by default, gradients are\n",
    "        # accumulated in buffers (i.e, not overwritten) whenever .backward()\n",
    "        # is called. Checkout docs of torch.autograd.backward for more details.\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Calling the step function on an Optimizer makes an update to its\n",
    "        # parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "    # Print progress (here evaluating on all the data so we can compare)\n",
    "    if t % 10 == 0:\n",
    "        loss = loss_fn(model(x), y)\n",
    "        loss_test = loss_fn(model(x_test), y_test)\n",
    "        print(t, \"train:\", loss.item(), \"| test:\", loss_test.item())\n",
    "        if (dt.now() - t_start).seconds > tmax:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So with a drop-out on the hidden layer, this high, we have much slower learning in our network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general this small network is not optimal for playing with regularization, because it is so small that little regularization is required anyway. Next week, however, we will be working with some networks that very much require regularization in order to not overfit."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
